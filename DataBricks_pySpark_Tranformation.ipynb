{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f811ec4-0043-4fb5-a9a3-d621205bdc7b",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Data Ingestion and Transformation using DataBricks (PySpark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54ba23f7-03fb-4ab8-b579-d117660ee132",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e02d82b-944f-4c63-8f59-4e505b98730c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType, DoubleType, BooleanType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba022360-03dd-4556-b116-570e140719e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "\"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "\"fs.azure.account.oauth2.client.id\": \"\",\n",
    "\"fs.azure.account.oauth2.client.secret\": '',\n",
    "\"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com//oauth2/token\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5e43800-8d11-4954-b846-4dbc573d3edf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Mounting Data from Azure Data lake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ffc6844-622c-4a36-b2d1-3286607d4a02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mExecutionError\u001b[0m                            Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-352692405588868>, line 1\u001b[0m\n",
       "\u001b[0;32m----> 1\u001b[0m \u001b[43mdbutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmount\u001b[49m\u001b[43m(\u001b[49m\n",
       "\u001b[1;32m      2\u001b[0m \u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabfss://tokyo-olypmics-data@tokyoolympicsdataudbhav.dfs.core.windows.net/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# contrainer@storageacc\u001b[39;49;00m\n",
       "\u001b[1;32m      3\u001b[0m \u001b[43mmount_point\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/tokyoolymic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
       "\u001b[1;32m      4\u001b[0m \u001b[43mextra_configs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n",
       "\n",
       "File \u001b[0;32m/databricks/python_shell/dbruntime/dbutils.py:362\u001b[0m, in \u001b[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
       "\u001b[1;32m    360\u001b[0m exc\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[1;32m    361\u001b[0m exc\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\u001b[0;32m--> 362\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
       "\n",
       "\u001b[0;31mExecutionError\u001b[0m: An error occurred while calling o391.mount.\n",
       ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/tokyoolymic; nested exception is: \n",
       "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/tokyoolymic\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1053)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1079)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:667)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:685)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:71)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:71)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:662)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:580)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:71)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:540)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:71)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:135)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1073)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/tokyoolymic\n",
       "\tat scala.Predef$.require(Predef.scala:281)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:703)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1085)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:858)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1074)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:711)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:436)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:436)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:335)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:525)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:629)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:647)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:624)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:534)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:526)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:494)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:546)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:57)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:546)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:524)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:178)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:106)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:106)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:150)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:147)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:88)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:840)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecutionError\u001b[0m                            Traceback (most recent call last)\nFile \u001b[0;32m<command-352692405588868>, line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdbutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmount\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mabfss://tokyo-olypmics-data@tokyoolympicsdataudbhav.dfs.core.windows.net/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# contrainer@storageacc\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43mmount_point\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/tokyoolymic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43mextra_configs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n\nFile \u001b[0;32m/databricks/python_shell/dbruntime/dbutils.py:362\u001b[0m, in \u001b[0;36mDBUtils.FSHandler.prettify_exception_message.<locals>.f_with_exception_handling\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m exc\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    361\u001b[0m exc\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n\n\u001b[0;31mExecutionError\u001b[0m: An error occurred while calling o391.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/tokyoolymic; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/tokyoolymic\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1053)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1079)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:571)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:667)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:685)\n\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:196)\n\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:470)\n\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:662)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:580)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:71)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:571)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:540)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:71)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:135)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1073)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/tokyoolymic\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:703)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1085)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:858)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1074)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:711)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:436)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:436)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:335)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:525)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:629)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:647)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:624)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:534)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:526)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:494)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:546)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:57)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:546)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:524)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:178)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:106)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:244)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:240)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:106)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:150)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:147)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:88)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n",
       "errorSummary": "java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/tokyoolymic; nested exception is: ",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.mount(\n",
    "source = \"abfss://tokyo-olypmics-data@tokyoolympicsdataudbhav.dfs.core.windows.net/\", # contrainer@storageacc\n",
    "mount_point = \"/mnt/tokyoolymic\",\n",
    "extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1023e4c4-4042-4c65-95e3-e8d442499622",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/tokyoolymic/raw-data/</td><td>raw-data/</td><td>0</td><td>1716659533000</td></tr><tr><td>dbfs:/mnt/tokyoolymic/transformed-data/</td><td>transformed-data/</td><td>0</td><td>1716659542000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/tokyoolymic/raw-data/",
         "raw-data/",
         0,
         1716659533000
        ],
        [
         "dbfs:/mnt/tokyoolymic/transformed-data/",
         "transformed-data/",
         0,
         1716659542000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"/mnt/tokyoolymic\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa202eef-62ad-48eb-8543-0440eeee3c01",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Reading data into databricks from Azure Data lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93346cda-2e8c-4a2d-aa32-0f374ac22ba4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "athletes = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"/mnt/tokyoolymic/raw-data/Athlete.csv\")\n",
    "coaches = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"/mnt/tokyoolymic/raw-data/Coaches.csv\")\n",
    "entriesgender = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"/mnt/tokyoolymic/raw-data/EntriesGender.csv\")\n",
    "medals = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"/mnt/tokyoolymic/raw-data/Medals.csv\")\n",
    "teams = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"/mnt/tokyoolymic/raw-data/Teams.csv\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9bd0457-3b1c-48b2-9f62-46a8b6b31846",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PersonName: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Discipline: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athletes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2ddccee-5442-4a44-ab58-43f08a6220e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|          PersonName|             Country|         Discipline|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|     AALERUD Katrine|              Norway|       Cycling Road|\n",
      "|         ABAD Nestor|               Spain|Artistic Gymnastics|\n",
      "|   ABAGNALE Giovanni|               Italy|             Rowing|\n",
      "|      ABALDE Alberto|               Spain|         Basketball|\n",
      "|       ABALDE Tamara|               Spain|         Basketball|\n",
      "|           ABALO Luc|              France|           Handball|\n",
      "|        ABAROA Cesar|               Chile|             Rowing|\n",
      "|       ABASS Abobakr|               Sudan|           Swimming|\n",
      "|    ABBASALI Hamideh|Islamic Republic ...|             Karate|\n",
      "|       ABBASOV Islam|          Azerbaijan|          Wrestling|\n",
      "|        ABBINGH Lois|         Netherlands|           Handball|\n",
      "|         ABBOT Emily|           Australia|Rhythmic Gymnastics|\n",
      "|       ABBOTT Monica|United States of ...|  Baseball/Softball|\n",
      "|ABDALLA Abubaker ...|               Qatar|          Athletics|\n",
      "|      ABDALLA Maryam|               Egypt|  Artistic Swimming|\n",
      "|      ABDALLAH Shahd|               Egypt|  Artistic Swimming|\n",
      "| ABDALRASOOL Mohamed|               Sudan|               Judo|\n",
      "|   ABDEL LATIF Radwa|               Egypt|           Shooting|\n",
      "|    ABDEL RAZEK Samy|               Egypt|           Shooting|\n",
      "|   ABDELAZIZ Abdalla|               Egypt|             Karate|\n",
      "+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athletes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36a98e44-6af7-4ff3-b634-54cb6e142625",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Discipline: string (nullable = true)\n",
      " |-- Event: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coaches.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b7c75a-e1dd-44cc-b030-d7bc3680ee61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+--------+\n",
      "|                Name|             Country|       Discipline|   Event|\n",
      "+--------------------+--------------------+-----------------+--------+\n",
      "|     ABDELMAGID Wael|               Egypt|         Football|    NULL|\n",
      "|           ABE Junya|               Japan|       Volleyball|    NULL|\n",
      "|       ABE Katsuhiko|               Japan|       Basketball|    NULL|\n",
      "|        ADAMA Cherif|       Cï¿½te d'Ivoire|         Football|    NULL|\n",
      "|          AGEBA Yuya|               Japan|       Volleyball|    NULL|\n",
      "|AIKMAN Siegfried ...|               Japan|           Hockey|     Men|\n",
      "|       AL SAADI Kais|             Germany|           Hockey|     Men|\n",
      "|       ALAMEDA Lonni|              Canada|Baseball/Softball|Softball|\n",
      "|     ALEKNO Vladimir|Islamic Republic ...|       Volleyball|     Men|\n",
      "|     ALEKSEEV Alexey|                 ROC|         Handball|   Women|\n",
      "|ALLER CARBALLO Ma...|               Spain|       Basketball|    NULL|\n",
      "|       ALSHEHRI Saad|        Saudi Arabia|         Football|     Men|\n",
      "|           ALY Kamal|               Egypt|         Football|    NULL|\n",
      "| AMAYA GAITAN Fabian|         Puerto Rico|       Basketball|    NULL|\n",
      "|    AMO AGUADO Pablo|               Spain|         Football|    NULL|\n",
      "|   ANDONOVSKI Vlatko|United States of ...|         Football|   Women|\n",
      "|        ANNAN Alyson|         Netherlands|           Hockey|   Women|\n",
      "|  ARNAU CREUS Xavier|               Japan|           Hockey|   Women|\n",
      "|       ARNOLD Graham|           Australia|         Football|     Men|\n",
      "|         AXNER Tomas|              Sweden|         Handball|   Women|\n",
      "+--------------------+--------------------+-----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coaches.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adfc78e3-1491-4241-9c4f-174a2ad2046d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Discipline: string (nullable = true)\n",
      " |-- Female: integer (nullable = true)\n",
      " |-- Male: integer (nullable = true)\n",
      " |-- Total: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entriesgender.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7db4e6c-0576-4a29-833a-f385beee42d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----+-----+\n",
      "|          Discipline|Female|Male|Total|\n",
      "+--------------------+------+----+-----+\n",
      "|      3x3 Basketball|    32|  32|   64|\n",
      "|             Archery|    64|  64|  128|\n",
      "| Artistic Gymnastics|    98|  98|  196|\n",
      "|   Artistic Swimming|   105|   0|  105|\n",
      "|           Athletics|   969|1072| 2041|\n",
      "|           Badminton|    86|  87|  173|\n",
      "|   Baseball/Softball|    90| 144|  234|\n",
      "|          Basketball|   144| 144|  288|\n",
      "|    Beach Volleyball|    48|  48|   96|\n",
      "|              Boxing|   102| 187|  289|\n",
      "|        Canoe Slalom|    41|  41|   82|\n",
      "|        Canoe Sprint|   123| 126|  249|\n",
      "|Cycling BMX Frees...|    10|   9|   19|\n",
      "|  Cycling BMX Racing|    24|  24|   48|\n",
      "|Cycling Mountain ...|    38|  38|   76|\n",
      "|        Cycling Road|    70| 131|  201|\n",
      "|       Cycling Track|    90|  99|  189|\n",
      "|              Diving|    72|  71|  143|\n",
      "|          Equestrian|    73| 125|  198|\n",
      "|             Fencing|   107| 108|  215|\n",
      "+--------------------+------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entriesgender.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2817d65-ed4c-4db9-a030-b00ba4888797",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Rank: integer (nullable = true)\n",
      " |-- Team_Country: string (nullable = true)\n",
      " |-- Gold: integer (nullable = true)\n",
      " |-- Silver: integer (nullable = true)\n",
      " |-- Bronze: integer (nullable = true)\n",
      " |-- Total: integer (nullable = true)\n",
      " |-- Rank by Total: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medals.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd2efed5-0c11-43f3-8ac9-e810acebbc3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----+------+------+-----+-------------+\n",
      "|Rank|        Team_Country|Gold|Silver|Bronze|Total|Rank by Total|\n",
      "+----+--------------------+----+------+------+-----+-------------+\n",
      "|   1|United States of ...|  39|    41|    33|  113|            1|\n",
      "|   2|People's Republic...|  38|    32|    18|   88|            2|\n",
      "|   3|               Japan|  27|    14|    17|   58|            5|\n",
      "|   4|       Great Britain|  22|    21|    22|   65|            4|\n",
      "|   5|                 ROC|  20|    28|    23|   71|            3|\n",
      "|   6|           Australia|  17|     7|    22|   46|            6|\n",
      "|   7|         Netherlands|  10|    12|    14|   36|            9|\n",
      "|   8|              France|  10|    12|    11|   33|           10|\n",
      "|   9|             Germany|  10|    11|    16|   37|            8|\n",
      "|  10|               Italy|  10|    10|    20|   40|            7|\n",
      "|  11|              Canada|   7|     6|    11|   24|           11|\n",
      "|  12|              Brazil|   7|     6|     8|   21|           12|\n",
      "|  13|         New Zealand|   7|     6|     7|   20|           13|\n",
      "|  14|                Cuba|   7|     3|     5|   15|           18|\n",
      "|  15|             Hungary|   6|     7|     7|   20|           13|\n",
      "|  16|   Republic of Korea|   6|     4|    10|   20|           13|\n",
      "|  17|              Poland|   4|     5|     5|   14|           19|\n",
      "|  18|      Czech Republic|   4|     4|     3|   11|           23|\n",
      "|  19|               Kenya|   4|     4|     2|   10|           25|\n",
      "|  20|              Norway|   4|     2|     2|    8|           29|\n",
      "+----+--------------------+----+------+------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a41d68-d923-4a17-9a1c-3c7e8bbcea40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TeamName: string (nullable = true)\n",
      " |-- Discipline: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Event: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cb35f89-64b6-4cb5-919f-41d21a490f5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+--------------------+------------+\n",
      "|     TeamName|    Discipline|             Country|       Event|\n",
      "+-------------+--------------+--------------------+------------+\n",
      "|      Belgium|3x3 Basketball|             Belgium|         Men|\n",
      "|        China|3x3 Basketball|People's Republic...|         Men|\n",
      "|        China|3x3 Basketball|People's Republic...|       Women|\n",
      "|       France|3x3 Basketball|              France|       Women|\n",
      "|        Italy|3x3 Basketball|               Italy|       Women|\n",
      "|        Japan|3x3 Basketball|               Japan|         Men|\n",
      "|        Japan|3x3 Basketball|               Japan|       Women|\n",
      "|       Latvia|3x3 Basketball|              Latvia|         Men|\n",
      "|     Mongolia|3x3 Basketball|            Mongolia|       Women|\n",
      "|  Netherlands|3x3 Basketball|         Netherlands|         Men|\n",
      "|       Poland|3x3 Basketball|              Poland|         Men|\n",
      "|          ROC|3x3 Basketball|                 ROC|         Men|\n",
      "|          ROC|3x3 Basketball|                 ROC|       Women|\n",
      "|      Romania|3x3 Basketball|             Romania|       Women|\n",
      "|       Serbia|3x3 Basketball|              Serbia|         Men|\n",
      "|United States|3x3 Basketball|United States of ...|       Women|\n",
      "|    Australia|       Archery|           Australia|  Men's Team|\n",
      "|    Australia|       Archery|           Australia|  Mixed Team|\n",
      "|   Bangladesh|       Archery|          Bangladesh|  Mixed Team|\n",
      "|      Belarus|       Archery|             Belarus|Women's Team|\n",
      "+-------------+--------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b02dade-cb33-4b3f-ad48-adf5e9277851",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Cleaning and tranformations\n",
    "##### Finding Nulls in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44474ba8-ab4b-4393-85e9-8a2ff356d20f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+\n",
      "|PersonName|Country|Discipline|\n",
      "+----------+-------+----------+\n",
      "|         0|      0|         0|\n",
      "+----------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "athletes_nulls = athletes.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in athletes.columns])\n",
    "athletes_nulls.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "159e8485-6166-4765-b6b0-ed8e9bcc4269",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+-----+\n",
      "|Name|Country|Discipline|Event|\n",
      "+----+-------+----------+-----+\n",
      "|   0|      0|         0|  145|\n",
      "+----+-------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coaches_nulls = coaches.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in coaches.columns])\n",
    "coaches_nulls.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "080a3aea-2e31-4b43-8204-5177d4530d4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+-----+\n",
      "|Discipline|Female|Male|Total|\n",
      "+----------+------+----+-----+\n",
      "|         0|     0|   0|    0|\n",
      "+----------+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entriesgender_nulls = entriesgender.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in entriesgender.columns])\n",
    "entriesgender_nulls.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "292be521-2a9f-425f-9c61-ea69ddb1ace0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+----+------+------+-----+-------------+\n",
      "|Rank|Team_Country|Gold|Silver|Bronze|Total|Rank by Total|\n",
      "+----+------------+----+------+------+-----+-------------+\n",
      "|   0|           0|   0|     0|     0|    0|            0|\n",
      "+----+------------+----+------+------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medals_nulls = medals.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in medals.columns])\n",
    "medals_nulls.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e26fe17-2dab-4495-8686-5754d8be9c8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------+-----+\n",
      "|TeamName|Discipline|Country|Event|\n",
      "+--------+----------+-------+-----+\n",
      "|       0|         0|      0|    0|\n",
      "+--------+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teams_nulls = teams.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in teams.columns])\n",
    "teams_nulls.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ba753c9-970a-4a2b-a6f4-768551fa2df3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### We saw that Coaches table has 145 nulls in Event column. Let's impute it as 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e5456ce-87fe-4251-9c9d-512ca6ef10e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+-------+\n",
      "|                Name|             Country|       Discipline|  Event|\n",
      "+--------------------+--------------------+-----------------+-------+\n",
      "|     ABDELMAGID Wael|               Egypt|         Football|Unknown|\n",
      "|           ABE Junya|               Japan|       Volleyball|Unknown|\n",
      "|       ABE Katsuhiko|               Japan|       Basketball|Unknown|\n",
      "|        ADAMA Cherif|       Cï¿½te d'Ivoire|         Football|Unknown|\n",
      "|          AGEBA Yuya|               Japan|       Volleyball|Unknown|\n",
      "|AIKMAN Siegfried ...|               Japan|           Hockey|    Men|\n",
      "|       AL SAADI Kais|             Germany|           Hockey|    Men|\n",
      "|       ALAMEDA Lonni|              Canada|Baseball/Softball|Unknown|\n",
      "|     ALEKNO Vladimir|Islamic Republic ...|       Volleyball|    Men|\n",
      "|     ALEKSEEV Alexey|                 ROC|         Handball|  Women|\n",
      "|ALLER CARBALLO Ma...|               Spain|       Basketball|Unknown|\n",
      "|       ALSHEHRI Saad|        Saudi Arabia|         Football|    Men|\n",
      "|           ALY Kamal|               Egypt|         Football|Unknown|\n",
      "| AMAYA GAITAN Fabian|         Puerto Rico|       Basketball|Unknown|\n",
      "|    AMO AGUADO Pablo|               Spain|         Football|Unknown|\n",
      "|   ANDONOVSKI Vlatko|United States of ...|         Football|  Women|\n",
      "|        ANNAN Alyson|         Netherlands|           Hockey|  Women|\n",
      "|  ARNAU CREUS Xavier|               Japan|           Hockey|  Women|\n",
      "|       ARNOLD Graham|           Australia|         Football|    Men|\n",
      "|         AXNER Tomas|              Sweden|         Handball|  Women|\n",
      "+--------------------+--------------------+-----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, lit\n",
    "# Impute null values in the 'Event' column with 'Unknown' only for rows with invalid events\n",
    "coaches = coaches.withColumn('Event', when(~col('Event').isin('Men', 'Women'), lit('Unknown')).otherwise(col('Event')))\n",
    "coaches = coaches.fillna({'Event': 'Unknown'})\n",
    "# Show the result to verify\n",
    "coaches.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ada724aa-728e-48c6-a410-4036e3cb4aaa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Splitting the Name into first and last Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd19319-f655-4e19-adc5-f4eab8d273b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-----------+--------+\n",
      "|          PersonName|             Country|         Discipline|  FirstName|LastName|\n",
      "+--------------------+--------------------+-------------------+-----------+--------+\n",
      "|     AALERUD Katrine|              Norway|       Cycling Road|    AALERUD| Katrine|\n",
      "|         ABAD Nestor|               Spain|Artistic Gymnastics|       ABAD|  Nestor|\n",
      "|   ABAGNALE Giovanni|               Italy|             Rowing|   ABAGNALE|Giovanni|\n",
      "|      ABALDE Alberto|               Spain|         Basketball|     ABALDE| Alberto|\n",
      "|       ABALDE Tamara|               Spain|         Basketball|     ABALDE|  Tamara|\n",
      "|           ABALO Luc|              France|           Handball|      ABALO|     Luc|\n",
      "|        ABAROA Cesar|               Chile|             Rowing|     ABAROA|   Cesar|\n",
      "|       ABASS Abobakr|               Sudan|           Swimming|      ABASS| Abobakr|\n",
      "|    ABBASALI Hamideh|Islamic Republic ...|             Karate|   ABBASALI| Hamideh|\n",
      "|       ABBASOV Islam|          Azerbaijan|          Wrestling|    ABBASOV|   Islam|\n",
      "|        ABBINGH Lois|         Netherlands|           Handball|    ABBINGH|    Lois|\n",
      "|         ABBOT Emily|           Australia|Rhythmic Gymnastics|      ABBOT|   Emily|\n",
      "|       ABBOTT Monica|United States of ...|  Baseball/Softball|     ABBOTT|  Monica|\n",
      "|ABDALLA Abubaker ...|               Qatar|          Athletics|    ABDALLA|Abubaker|\n",
      "|      ABDALLA Maryam|               Egypt|  Artistic Swimming|    ABDALLA|  Maryam|\n",
      "|      ABDALLAH Shahd|               Egypt|  Artistic Swimming|   ABDALLAH|   Shahd|\n",
      "| ABDALRASOOL Mohamed|               Sudan|               Judo|ABDALRASOOL| Mohamed|\n",
      "|   ABDEL LATIF Radwa|               Egypt|           Shooting|      ABDEL|   LATIF|\n",
      "|    ABDEL RAZEK Samy|               Egypt|           Shooting|      ABDEL|   RAZEK|\n",
      "|   ABDELAZIZ Abdalla|               Egypt|             Karate|  ABDELAZIZ| Abdalla|\n",
      "+--------------------+--------------------+-------------------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "athletes = athletes.withColumn('FirstName', split(col('PersonName'), ' ')[0]) \\\n",
    "                                .withColumn('LastName', split(col('PersonName'), ' ')[1])\n",
    "\n",
    "athletes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0b97126-c2d0-4a75-8e0f-6e8c22d4550d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Convert String Columns to Proper Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cb019f8-d8e9-4731-9d77-309d1f14f809",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import initcap\n",
    "\n",
    "# Convert string columns to proper case\n",
    "athletes_transformed = athletes.withColumn('Country', initcap(col('Country'))) \\\n",
    "                               .withColumn('Discipline', initcap(col('Discipline')))\n",
    "\n",
    "coaches_transformed = coaches.withColumn('Country', initcap(col('Country'))) \\\n",
    "                             .withColumn('Discipline', initcap(col('Discipline'))) \\\n",
    "                             .withColumn('Event', initcap(col('Event')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0de01f5-706a-4469-882f-deea5932e00b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-------------------+---------+--------+\n",
      "|       PersonName|Country|         Discipline|FirstName|LastName|\n",
      "+-----------------+-------+-------------------+---------+--------+\n",
      "|  AALERUD Katrine| Norway|       Cycling Road|  AALERUD| Katrine|\n",
      "|      ABAD Nestor|  Spain|Artistic Gymnastics|     ABAD|  Nestor|\n",
      "|ABAGNALE Giovanni|  Italy|             Rowing| ABAGNALE|Giovanni|\n",
      "|   ABALDE Alberto|  Spain|         Basketball|   ABALDE| Alberto|\n",
      "|    ABALDE Tamara|  Spain|         Basketball|   ABALDE|  Tamara|\n",
      "+-----------------+-------+-------------------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athletes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0641286-c9ea-499d-b878-bd1310df8c7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+----------+-------+\n",
      "|           Name|      Country|Discipline|  Event|\n",
      "+---------------+-------------+----------+-------+\n",
      "|ABDELMAGID Wael|        Egypt|  Football|Unknown|\n",
      "|      ABE Junya|        Japan|Volleyball|Unknown|\n",
      "|  ABE Katsuhiko|        Japan|Basketball|Unknown|\n",
      "|   ADAMA Cherif|Cï¿½te d'Ivoire|  Football|Unknown|\n",
      "|     AGEBA Yuya|        Japan|Volleyball|Unknown|\n",
      "+---------------+-------------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coaches.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6accac75-e1b5-4b5b-8ecd-9738a34917b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Loading into Datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4538f2d6-d87c-4765-8fd2-09f53b86536d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "athletes.repartition(1).write.mode(\"overwrite\").option(\"header\",'true').csv(\"/mnt/tokyoolymic/transformed-data/athletes\")\n",
    "coaches.repartition(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"/mnt/tokyoolymic/transformed-data/coaches\")\n",
    "entriesgender.repartition(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"/mnt/tokyoolymic/transformed-data/entriesgender\")\n",
    "medals.repartition(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"/mnt/tokyoolymic/transformed-data/medals\")\n",
    "teams.repartition(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(\"/mnt/tokyoolymic/transformed-data/teams\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Tokyo-Olympics-2020 2024-05-25 13:48:05",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
